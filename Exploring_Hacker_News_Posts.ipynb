{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9722373c",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb755e20",
   "metadata": {},
   "source": [
    "![Image](https://s3.amazonaws.com/dq-content/354/hacker_news.jpg)\n",
    "\n",
    "This project is about analyzing information from the Hacker News Posts (HN) dataset of submissions to a technology site [Hacker News](http://news.ycombinator.com/). Hacker News is a site where user-submitted stories (known as \"posts\") receive votes and comments and, depending on a number of positive or negative votes, can be raised in the feed of posts or lowered down, similar to reddit.\n",
    "\n",
    "You can find the the Hacker News Posts dataset [here](http://www.kaggle.com/hacker-news/hacker-news-posts), but note that we have reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "- `id`: the unique identifier from Hacker News for the post;\n",
    "- `title`: the title of the post;\n",
    "- `url`: the URL that the posts links to, if the post has a URL;\n",
    "- `num_points`: the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes;\n",
    "- `num_comments`: the number of comments on the post;\n",
    "- `author`: the username of the person who submitted the post;\n",
    "- `created_at`: the date and time of the post's submission.\n",
    "\n",
    "We are specifically interested in posts with titles that begin with either \"Ask HN\" or \"Show HN\". Users submit \"Ask HN\" posts to ask the Hacker News community a specific question. Likewise, users submit \"Show HN\" posts to show the Hacker News community a project, product, or just something interesting. We will compare these two types of posts to determine the following:\n",
    "- Do \"Ask HN\" or \"Show HN\" receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de8cf0",
   "metadata": {},
   "source": [
    "### Opening and exploring the data\n",
    "First of all, to start working with the information stored in the dataset we will have to extract it from a `CSV` file and assign it to the `hn` variable. To do it, we will import the `reader`class from the `csv` module and use the `extract_data` function that takes an argument `directory`. The function returns information from the dataset in the \"list of lists\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ace1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "from csv import reader\n",
    "def extract_data(directory):\n",
    "    OpenedDataset = open(directory, encoding = \"utf8\")\n",
    "    ReadData = reader(OpenedDataset)\n",
    "    return list(ReadData)\n",
    "HN = extract_data('..\\..\\Datasets\\P2_Exploring_Hacker_News_Posts\\hacker_news.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd362aa",
   "metadata": {},
   "source": [
    "To have a first look at the data from the Hacker News dataset we will write the `explore_data` function that takes 4 arguments:\n",
    "1. `dataset` - a title of the dataset.\n",
    "2. `start and end` - the start and the end indexes of a given dataset to display a certain number of rows that we want to display.\n",
    "3. `rows_and_columns` - this argument is used to indicate if we need to display the aggregated information about a number of rows and a number of columns on the interval of rows chosen in the previous step. The argument is \"False\" by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0ec46",
   "metadata": {},
   "source": [
    "Let's use the `explore_data` function to display first five rows to have a first look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60425c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(HN, 0, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddc6a3",
   "metadata": {},
   "source": [
    "Notice that the first list in the inner lists contains the column `headers`. In the next step we will extract the first row of data, and assign it to the variable `headers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d703cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']]\n"
     ]
    }
   ],
   "source": [
    "headers = HN[:1]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a272b7c",
   "metadata": {},
   "source": [
    "In the next step we will remove the column `headers` from the `HN` list and use the function `explore_data` to display first five rows to verify that we removed the header row properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb790e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HN = HN[1:]\n",
    "explore_data(HN, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c711669",
   "metadata": {},
   "source": [
    "Since we are only concerned with post titles beginning with \"Ask HN\" or \"Show HN\", we will create new lists of lists containing just the data for those titles. To find the posts that begin with either \"Ask HN\" or \"Show HN\", we will use the string method `startswith`. The method will return `True` if the given string object the string parametr starts with a substring given as an argument. Notice what capitalization matters, so we could will be using the string method `lower`, which returns a lowercase version of the starting string. Let's use these methods to separate posts beginning with \"Ask HN\" and \"Show HN\" (and case variations) into two different lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc95cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in the list 'ask_posts' is 1744 \n",
      "\n",
      "The number of posts in the list 'show_posts' is 1162 \n",
      "\n",
      "The number of posts in the list 'show_posts' is 17194 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for data in HN:\n",
    "    title = data[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(data)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(data)\n",
    "    else:\n",
    "        other_posts.append(data)\n",
    "print(\"The number of posts in the list 'ask_posts' is {list}\".format(list = len(ask_posts)), \"\\n\")\n",
    "print(\"The number of posts in the list 'show_posts' is {list}\".format(list = len(show_posts)), \"\\n\")\n",
    "print(\"The number of posts in the list 'show_posts' is {list}\".format(list = len(other_posts)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08cbde",
   "metadata": {},
   "source": [
    "Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06cb0323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments in the 'Ask HN' posts is 14.04 \n",
      "\n",
      "Average number of comments in the 'Show HN' posts is 10.32 \n",
      "\n",
      "Average number of comments in the 'Other' posts is 26.87 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def comments_summary(comments_list):\n",
    "    total_comments = 0\n",
    "    for data in comments_list:\n",
    "        num_comments = int(data[4])\n",
    "        total_comments += num_comments\n",
    "    return total_comments\n",
    "\n",
    "total_ask_comments = comments_summary(ask_posts)\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(\"Average number of comments in the 'Ask HN' posts is {avg_ask_comments:.2f}\".format(avg_ask_comments = avg_ask_comments), \"\\n\")\n",
    "\n",
    "total_show_comments = comments_summary(show_posts)\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(\"Average number of comments in the 'Show HN' posts is {avg_show_comments:.2f}\".format(avg_show_comments = avg_show_comments), \"\\n\")\n",
    "\n",
    "total_other_comments = comments_summary(other_posts)\n",
    "avg_other_comments = total_other_comments/len(other_posts)\n",
    "print(\"Average number of comments in the 'Other' posts is {avg_other_comments:.2f}\".format(avg_other_comments = avg_other_comments), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7552fe89",
   "metadata": {},
   "source": [
    "As we can see in the output the theory what \"Ask HN\" posts or \"Show HN\" posts receive more comments on average in comparison with other posts is wrong. Another thing that can see from the output is that, on average, ask posts receive more comments than show posts. Since \"Ask HN\" posts are more likely to receive comments, we will focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we will determine if \"Ask HN\" posts created at a certain time are more likely to attract comments. We will use the following steps to perform this analysis:\n",
    "1. Calculate the number of \"Ask HN\" posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments \"Ask HN\" posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7972e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for data in ask_posts:\n",
    "    result_list = []\n",
    "    created_at = data[6]\n",
    "    comments_number = int(data[4])\n",
    "    result_list.append(created_at)\n",
    "    result_list.append(comments_number)\n",
    "    results_list.append(result_list)\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for data in results_list:\n",
    "    date_time_dt = dt.strptime(data[0], '%m/%d/%Y %H:%M')\n",
    "    hour_dt = int(date_time_dt.hour)\n",
    "    if hour_dt not in counts_by_hour:\n",
    "        counts_by_hour[hour_dt] = 1\n",
    "        comments_by_hour[hour_dt] = data[1]\n",
    "    else:\n",
    "        counts_by_hour[hour_dt] += 1\n",
    "        comments_by_hour[hour_dt] += data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a993540",
   "metadata": {},
   "source": [
    "Let's make sure what everything works correctly. To do it we will print examples of values of the dictionaries `counts_by_hour` and `comments_by_hour` with a key equal 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b97f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Ask HN' posts created at 6 am is 44 \n",
      "\n",
      "Number of comments in 'Ask HN' posts created at 6 am is 397 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of 'Ask HN' posts created at 6 am is {number}\".format(number = counts_by_hour[6]), \"\\n\")\n",
    "print(\"Number of comments in 'Ask HN' posts created at 6 am is {number}\".format(number = comments_by_hour[6]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f307b",
   "metadata": {},
   "source": [
    "Next, we will use the dictionaries `counts_by_hour` and `comments_by_hour` to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a40ce16d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 5.58], [13, 14.74], [10, 13.44], [14, 13.23], [16, 16.8], [23, 7.99], [12, 9.41], [17, 11.46], [15, 38.59], [21, 16.01], [20, 21.52], [2, 23.81], [18, 13.2], [3, 7.8], [5, 10.09], [19, 10.8], [1, 11.38], [22, 6.75], [8, 10.25], [4, 7.17], [0, 8.13], [6, 9.02], [7, 7.85], [11, 11.05]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, round(comments_by_hour[hour]/counts_by_hour[hour], 2)])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f064772",
   "metadata": {},
   "source": [
    "Let's display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea019769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments for the post created during from 9 to 10 is 5.58\n",
      "The average number of comments for the post created during from 13 to 14 is 14.74\n",
      "The average number of comments for the post created during from 10 to 11 is 13.44\n",
      "The average number of comments for the post created during from 14 to 15 is 13.23\n",
      "The average number of comments for the post created during from 16 to 17 is 16.8\n",
      "The average number of comments for the post created during from 23 to 24 is 7.99\n",
      "The average number of comments for the post created during from 12 to 13 is 9.41\n",
      "The average number of comments for the post created during from 17 to 18 is 11.46\n",
      "The average number of comments for the post created during from 15 to 16 is 38.59\n",
      "The average number of comments for the post created during from 21 to 22 is 16.01\n",
      "The average number of comments for the post created during from 20 to 21 is 21.52\n",
      "The average number of comments for the post created during from 2 to 3 is 23.81\n",
      "The average number of comments for the post created during from 18 to 19 is 13.2\n",
      "The average number of comments for the post created during from 3 to 4 is 7.8\n",
      "The average number of comments for the post created during from 5 to 6 is 10.09\n",
      "The average number of comments for the post created during from 19 to 20 is 10.8\n",
      "The average number of comments for the post created during from 1 to 2 is 11.38\n",
      "The average number of comments for the post created during from 22 to 23 is 6.75\n",
      "The average number of comments for the post created during from 8 to 9 is 10.25\n",
      "The average number of comments for the post created during from 4 to 5 is 7.17\n",
      "The average number of comments for the post created during from 0 to 1 is 8.13\n",
      "The average number of comments for the post created during from 6 to 7 is 9.02\n",
      "The average number of comments for the post created during from 7 to 8 is 7.85\n",
      "The average number of comments for the post created during from 11 to 12 is 11.05\n"
     ]
    }
   ],
   "source": [
    "for data in avg_by_hour:\n",
    "    print(\"The average number of comments for the post created during from {hour_start} to {hour_end} is {avg_number}\".format(hour_start = data[0], hour_end = data[0] + 1, avg_number = data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116d867",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it difficult to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d216e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.58, 9], [14.74, 13], [13.44, 10], [13.23, 14], [16.8, 16], [7.99, 23], [9.41, 12], [11.46, 17], [38.59, 15], [16.01, 21], [21.52, 20], [23.81, 2], [13.2, 18], [7.8, 3], [10.09, 5], [10.8, 19], [11.38, 1], [6.75, 22], [10.25, 8], [7.17, 4], [8.13, 0], [9.02, 6], [7.85, 7], [11.05, 11]]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for data in avg_by_hour:\n",
    "    swap_avg_by_hour.append([data[1], data[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9e28",
   "metadata": {},
   "source": [
    "Let's use the built in function `sorted()` to sort `swap_avg_by_hour` in descending order. Since the first column of this list is the average number of comments, sorting the list will sort by the average number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17895f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' posts Comments:\n",
      "15:00: 38.59 average comments per post\n",
      "2:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.8 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print(\"Top 5 Hours for 'Ask HN' posts Comments:\")\n",
    "for data in sorted_swap[:5]:\n",
    "    print(\"{time}:00: {comments} average comments per post\".format(time = data[1], comments = data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246e317",
   "metadata": {},
   "source": [
    "If we refer back to [the documentation](https://www.kaggle.com/hacker-news/hacker-news-posts) for the dataset we would see from the description that the time zone in the column `created_at` is Eastern Time in the US. Since we live in Moscow where time zone is EST +8, in order to answer the question \"During which hours should we create a post to have a higher chance of receiving comments?\" we have to loop through the list `sorted_swap` and add 8 hours to every hour.\n",
    "To do it, we will use the built in method `timedelta` from the module `datettime`. There is a one problem: at this moment hours in the list `sorted_swap` stored in the format `int`, but the method `timedelta` works with data stored as the `timedelta` object. To solve the problem we will change the type `int` to `string` and then use the method `strptime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9126f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:00: 38.59 average comments per post\n",
      "10:00: 23.81 average comments per post\n",
      "4:00: 21.52 average comments per post\n",
      "0:00: 16.8 average comments per post\n",
      "5:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap_EST8 = []\n",
    "\n",
    "for data in sorted_swap:\n",
    "    hours_dt = dt.strptime(str(data[1]), '%H')\n",
    "    hours_to_add = timedelta(hours = 8)\n",
    "    hours = int((hours_dt + hours_to_add).strftime(\"%H\"))\n",
    "    sorted_swap_EST8.append([data[0], hours])\n",
    "\n",
    "for data in sorted_swap_EST8[:5]:\n",
    "    print(\"{time}:00: {comments} average comments per post\".format(time = data[1], comments = data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4e64d",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae06002",
   "metadata": {},
   "source": [
    "In this project, we analyzed data from the Hacker News Posts (HN) [data set](https://www.kaggle.com/hacker-news/hacker-news-posts) in order to answer two questions:\n",
    "1. Do posts with titles that begin with either \"Ask HN\" or \"Show HN\" receive more comments on average and, accordingly, have a higher position in the feed of posts.\n",
    "2. Do posts created at a certain time receive more comments on average and, if it is so, which time users should create posts to get a higher number of comments.\n",
    "\n",
    "To answer on the first question we can take a look on the output of `In[7]`. From the output we can make a conclusion that \"Ask HN\" posts or \"Show HN\" receive less comments on average in comparison with other posts, but at the same time we can say that, on average, \"Ask HN\" posts receive more comments than \"Show HN\" posts.\n",
    "\n",
    "To answer on the second question we can take a look on the output of `In[13]`and `In[14]`. From the outputs we can make a conclusion that to get a higher number of comments users should create posts at `15:00, 2:00, 20:00, 16:00, 21:00` EST +0 or at `23:00, 10:00, 4:00, 0:00, 5:00` EST +8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
